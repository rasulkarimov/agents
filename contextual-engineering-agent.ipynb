{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import types # Import the types module\n",
        "\n",
        "from typing import Any, Callable, Sequence\n",
        "import inspect\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Define the function to convert positional-only functions to tools\n",
        "def convert_positional_only_function_to_tool(function: Callable) -> Any:\n",
        "    \"\"\"\n",
        "    Converts a positional-only function to a LangChain tool if possible.\n",
        "\n",
        "    This function inspects the function's signature. If it is a built-in\n",
        "    function with only positional-only arguments, it wraps it in a LangChain\n",
        "    tool. Otherwise, it returns None.\n",
        "\n",
        "    Args:\n",
        "        function: The function to convert.\n",
        "\n",
        "    Returns:\n",
        "        A LangChain tool or None if the function cannot be converted.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Inspect the function's signature\n",
        "        sig = inspect.signature(function)\n",
        "        parameters = sig.parameters\n",
        "\n",
        "        # Check if all parameters are positional-only\n",
        "        if all(\n",
        "            param.kind == inspect.Parameter.POSITIONAL_ONLY\n",
        "            for param in parameters.values()\n",
        "        ):\n",
        "            # Create a tool from the function\n",
        "            # You might need to add a description or other metadata depending on your needs\n",
        "            return tool(function)\n",
        "        else:\n",
        "            # Not a positional-only function, return None\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        # Handle cases where inspection might fail for certain built-ins\n",
        "        print(f\"Could not convert function {function.__name__}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Collect functions from `math` built-in\n",
        "all_tools = []\n",
        "for function_name in dir(math):\n",
        "    function = getattr(math, function_name)\n",
        "    if not isinstance(\n",
        "        function, types.BuiltinFunctionType\n",
        "    ):\n",
        "        continue\n",
        "    # This is an idiosyncrasy of the `math` library\n",
        "    if tool := convert_positional_only_function_to_tool(\n",
        "        function\n",
        "    ):\n",
        "        all_tools.append(tool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edca637a-c675-4986-a67c-298a2dddeb49",
        "id": "AbFP02-WniOZ"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert function acosh: 'StructuredTool' object is not callable\n",
            "Could not convert function asin: 'NoneType' object is not callable\n",
            "Could not convert function asinh: 'NoneType' object is not callable\n",
            "Could not convert function atan: 'NoneType' object is not callable\n",
            "Could not convert function atan2: 'NoneType' object is not callable\n",
            "Could not convert function atanh: 'NoneType' object is not callable\n",
            "Could not convert function cbrt: 'NoneType' object is not callable\n",
            "Could not convert function ceil: 'NoneType' object is not callable\n",
            "Could not convert function comb: 'NoneType' object is not callable\n",
            "Could not convert function copysign: 'NoneType' object is not callable\n",
            "Could not convert function cos: 'NoneType' object is not callable\n",
            "Could not convert function cosh: 'NoneType' object is not callable\n",
            "Could not convert function degrees: 'NoneType' object is not callable\n",
            "Could not convert function dist: 'NoneType' object is not callable\n",
            "Could not convert function erf: 'NoneType' object is not callable\n",
            "Could not convert function erfc: 'NoneType' object is not callable\n",
            "Could not convert function exp: 'NoneType' object is not callable\n",
            "Could not convert function exp2: 'NoneType' object is not callable\n",
            "Could not convert function expm1: 'NoneType' object is not callable\n",
            "Could not convert function fabs: 'NoneType' object is not callable\n",
            "Could not convert function factorial: 'NoneType' object is not callable\n",
            "Could not convert function floor: 'NoneType' object is not callable\n",
            "Could not convert function fmod: 'NoneType' object is not callable\n",
            "Could not convert function frexp: 'NoneType' object is not callable\n",
            "Could not convert function fsum: 'NoneType' object is not callable\n",
            "Could not convert function gamma: 'NoneType' object is not callable\n",
            "Could not convert function hypot: no signature found for builtin <built-in function hypot>\n",
            "Could not convert function isfinite: 'NoneType' object is not callable\n",
            "Could not convert function isinf: 'NoneType' object is not callable\n",
            "Could not convert function isnan: 'NoneType' object is not callable\n",
            "Could not convert function isqrt: 'NoneType' object is not callable\n",
            "Could not convert function ldexp: 'NoneType' object is not callable\n",
            "Could not convert function lgamma: 'NoneType' object is not callable\n",
            "Could not convert function log: no signature found for builtin <built-in function log>\n",
            "Could not convert function log10: 'NoneType' object is not callable\n",
            "Could not convert function log1p: 'NoneType' object is not callable\n",
            "Could not convert function log2: 'NoneType' object is not callable\n",
            "Could not convert function modf: 'NoneType' object is not callable\n",
            "Could not convert function perm: 'NoneType' object is not callable\n",
            "Could not convert function pow: 'NoneType' object is not callable\n",
            "Could not convert function radians: 'NoneType' object is not callable\n",
            "Could not convert function remainder: 'NoneType' object is not callable\n",
            "Could not convert function sin: 'NoneType' object is not callable\n",
            "Could not convert function sinh: 'NoneType' object is not callable\n",
            "Could not convert function sqrt: 'NoneType' object is not callable\n",
            "Could not convert function sumprod: 'NoneType' object is not callable\n",
            "Could not convert function tan: 'NoneType' object is not callable\n",
            "Could not convert function tanh: 'NoneType' object is not callable\n",
            "Could not convert function trunc: 'NoneType' object is not callable\n",
            "Could not convert function ulp: 'NoneType' object is not callable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "iU3chfKwACff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict  # For defining the state schema with type hints\n",
        "\n",
        "from rich.console import Console  # For pretty-printing output\n",
        "from rich.pretty import pprint  # For pretty-printing Python objects\n",
        "\n",
        "# Initialize a console for rich, formatted output in the notebook.\n",
        "console = Console()"
      ],
      "metadata": {
        "id": "Nk-2j_iyAISG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the graph's state using TypedDict.\n",
        "# This class acts as a data structure that will be passed between nodes in the graph.\n",
        "# It ensures that the state has a consistent shape and provides type hints.\n",
        "class State(TypedDict):\n",
        "    \"\"\"\n",
        "    Defines the structure of the state for our joke generator workflow.\n",
        "\n",
        "    Attributes:\n",
        "        topic: The input topic for which a joke will be generated.\n",
        "        joke: The output field where the generated joke will be stored.\n",
        "    \"\"\"\n",
        "    topic: str\n",
        "    joke: str"
      ],
      "metadata": {
        "id": "iHav57LvAYtj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langgraph\n",
        "%pip install langchain-anthropic\n",
        "%pip install langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrZ_jg48CtOP",
        "outputId": "d7522590-325c-426d-abd8-79f821039dfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.2/471.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.4 langgraph-1.0.2 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-1.0.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting anthropic<1.0.0,>=0.69.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.72.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-anthropic) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-anthropic) (2.11.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (0.4.40)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.3->langchain-anthropic) (2.5.0)\n",
            "Downloading langchain_anthropic-1.0.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.72.0-py3-none-any.whl (357 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic, langchain-anthropic\n",
            "Successfully installed anthropic-0.72.0 langchain-anthropic-1.0.2\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.0.4)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.40)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for environment management, display, and LangGraph\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "from IPython.display import Image, display\n",
        "# from langchain.chat_models import init_chat_model # Remove this import\n",
        "from langchain_openai import ChatOpenAI # Import ChatOpenAI\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "\n",
        "from google.colab import userdata\n",
        "# --- Environment and Model Setup ---\n",
        "# Set the OpenAI API key to authenticate requests\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"Missing OPENAI_API_KEY in environment\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Initialize the chat model to be used in the workflow\n",
        "# We use a specific OpenAI model with temperature=0 for deterministic outputs\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0) # Use ChatOpenAI instead of init_chat_model\n",
        "\n",
        "# --- Define Workflow Node ---\n",
        "def generate_joke(state: State) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    A node function that generates a joke based on the topic in the current state.\n",
        "\n",
        "    This function reads the 'topic' from the state, uses the LLM to generate a joke,\n",
        "    and returns a dictionary to update the 'joke' field in the state.\n",
        "\n",
        "    Args:\n",
        "        state: The current state of the graph, which must contain a 'topic'.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with the 'joke' key to update the state.\n",
        "    \"\"\"\n",
        "    # Read the topic from the state\n",
        "    topic = state[\"topic\"]\n",
        "    print(f\"Generating a joke about: {topic}\")\n",
        "\n",
        "    # Invoke the language model to generate a joke\n",
        "    msg = llm.invoke(f\"Write a short joke about {topic}\")\n",
        "\n",
        "    # Return the generated joke to be written back to the state\n",
        "    return {\"joke\": msg.content}\n",
        "\n",
        "# --- Build and Compile the Graph ---\n",
        "# Initialize a new StateGraph with the predefined State schema\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add the 'generate_joke' function as a node in the graph\n",
        "workflow.add_node(\"generate_joke\", generate_joke)\n",
        "\n",
        "# Define the workflow's execution path:\n",
        "# The graph starts at the START entrypoint and flows to our 'generate_joke' node.\n",
        "workflow.add_edge(START, \"generate_joke\")\n",
        "# After 'generate_joke' completes, the graph execution ends.\n",
        "workflow.add_edge(\"generate_joke\", END)\n",
        "\n",
        "# Compile the workflow into an executable chain\n",
        "chain = workflow.compile()\n",
        "\n",
        "# --- Visualize the Graph ---\n",
        "# Display a visual representation of the compiled workflow graph\n",
        "display(Image(chain.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "J3sx5_EsAv1u",
        "outputId": "da895b46-d97e-4639-d3e2-6ae4eb182aaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Execute the Workflow ---\n",
        "# Invoke the compiled graph with an initial state containing the topic.\n",
        "# The `invoke` method runs the graph from the START node to the END node.\n",
        "joke_generator_state = chain.invoke({\"topic\": \"cats\"})\n",
        "\n",
        "# --- Display the Final State ---\n",
        "# Print the final state of the graph after execution.\n",
        "# This will show both the input 'topic' and the output 'joke' that was written to the state.\n",
        "console.print(\"\\n[bold blue]Joke Generator State:[/bold blue]\")\n",
        "pprint(joke_generator_state)\n",
        "\n",
        "\n",
        "\n",
        "#### OUTPUT ####\n",
        "{\n",
        "  'topic': 'cats',\n",
        "  'joke': 'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!'\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "UhFkw2i7G9Ug",
        "outputId": "ebd68278-6fdc-4daa-f388-fa086d2677c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating a joke about: cats\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;34mJoke Generator State:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Joke Generator State:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'topic': 'cats',\n",
              " 'joke': 'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Writing in LangGraph"
      ],
      "metadata": {
        "id": "kt-YJJO0MX0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "# --- Initialize Long-Term Memory Store ---\n",
        "# Create an instance of InMemoryStore, which provides a simple, non-persistent,\n",
        "# key-value storage system for use within the current session.\n",
        "store = InMemoryStore()\n",
        "\n",
        "# --- Define a Namespace for Organization ---\n",
        "# A namespace is used to logically group related data within the store.\n",
        "# Here, we use a tuple to represent a hierarchical namespace,\n",
        "# which could correspond to a user ID and an application context.\n",
        "namespace = (\"rlm\", \"joke_generator\")\n",
        "\n",
        "# --- Write Data to the Memory Store ---\n",
        "# Use the `put` method to save a key-value pair into the specified namespace.\n",
        "# This operation persists the joke generated in the previous step, making it\n",
        "# available for retrieval across different sessions or threads.\n",
        "store.put(namespace, \"last_joke\", {\"joke\": joke_generator_state[\"joke\"]})\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "avgqcHZjHc6L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search the namespace to view all stored items\n",
        "stored_items = list(store.search(namespace))\n",
        "\n",
        "# Display the stored items with rich formatting\n",
        "console.print(\"\\n[bold green]Stored Items in Memory:[/bold green]\")\n",
        "pprint(stored_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "OmwSr5mDM0QY",
        "outputId": "d2ae54f2-9667-4b15-d21c-7213c831e230"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;32mStored Items in Memory:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Stored Items in Memory:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnamespace\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'rlm'\u001b[0m, \u001b[32m'joke_generator'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mkey\u001b[0m=\u001b[32m'last_joke'\u001b[0m, \u001b[33mvalue\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mcreated_at\u001b[0m=\u001b[32m'2025-11-08T13:15:58.091218+00:00'\u001b[0m, \u001b[33mupdated_at\u001b[0m=\u001b[32m'2025-11-08T13:15:58.091224+00:00'\u001b[0m, \u001b[33mscore\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Item</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">namespace</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'rlm'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'joke_generator'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'last_joke'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">value</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-11-08T13:15:58.091218+00:00'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">updated_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-11-08T13:15:58.091224+00:00'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">score</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "# Initialize storage components\n",
        "checkpointer = InMemorySaver()  # For thread-level state persistence\n",
        "memory_store = InMemoryStore()  # For cross-thread memory storage\n",
        "\n",
        "\n",
        "def generate_joke(state: State, store: BaseStore) -> dict[str, str]:\n",
        "    \"\"\"Generate a joke with memory awareness.\n",
        "\n",
        "    This enhanced version checks for existing jokes in memory\n",
        "    before generating new ones.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the topic\n",
        "        store: Memory store for persistent context\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with the generated joke\n",
        "    \"\"\"\n",
        "    # Check if there's an existing joke in memory\n",
        "    existing_jokes = list(store.search(namespace))\n",
        "    if existing_jokes:\n",
        "        existing_joke = existing_jokes[0].value\n",
        "        print(f\"Existing joke: {existing_joke}\")\n",
        "    else:\n",
        "        print(\"Existing joke: No existing joke\")\n",
        "\n",
        "    # Generate a new joke based on the topic\n",
        "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
        "\n",
        "    # Store the new joke in long-term memory\n",
        "    store.put(namespace, \"last_joke\", {\"joke\": msg.content})\n",
        "\n",
        "    # Return the joke to be added to state\n",
        "    return {\"joke\": msg.content}\n",
        "\n",
        "\n",
        "# Build the workflow with memory capabilities\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add the memory-aware joke generation node\n",
        "workflow.add_node(\"generate_joke\", generate_joke)\n",
        "\n",
        "# Connect the workflow components\n",
        "workflow.add_edge(START, \"generate_joke\")\n",
        "workflow.add_edge(\"generate_joke\", END)\n",
        "\n",
        "# Compile with both checkpointing and memory store\n",
        "chain = workflow.compile(checkpointer=checkpointer, store=memory_store)"
      ],
      "metadata": {
        "id": "4p1deTrVN2T5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the workflow with thread-based configuration\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxbHJZGEPXh8",
        "outputId": "06999ca6-97c6-49aa-9fc0-a45db72fbc49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing joke: No existing joke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the workflow result with rich formatting\n",
        "console.print(\"\\n[bold cyan]Workflow Result (Thread 1):[/bold cyan]\")\n",
        "pprint(joke_generator_state)\n",
        "\n",
        "#### OUTPUT ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "bEmeRtvJSQTi",
        "outputId": "c5c6fc07-5413-4a66-d031-9360e5979077"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36mWorkflow Result \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mThread \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m)\u001b[0m\u001b[1;36m:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Workflow Result (Thread </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">):</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Retrieve and Inspect the Graph State ---\n",
        "# Use the `get_state` method to retrieve the latest state snapshot for the\n",
        "# thread specified in the `config` (in this case, thread \"1\"). This is\n",
        "# possible because we compiled the graph with a checkpointer.\n",
        "latest_state = chain.get_state(config)\n",
        "\n",
        "# --- Display the State Snapshot ---\n",
        "# Print the retrieved state to the console. The StateSnapshot includes not only\n",
        "# the data ('topic', 'joke') but also execution metadata.\n",
        "console.print(\"\\n[bold magenta]Latest Graph State (Thread 1):[/bold magenta]\")\n",
        "pprint(latest_state)\n",
        "\n",
        "# Execute the workflow with a different thread ID\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)\n",
        "\n",
        "# Display the result showing memory persistence across threads\n",
        "console.print(\"\\n[bold yellow]Workflow Result (Thread 2):[/bold yellow]\")\n",
        "pprint(joke_generator_state)\n",
        "\n",
        "#### OUTPUT ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "tjPDweLbSbyg",
        "outputId": "bfb7c5ef-5d76-4b10-e1cd-b6a15ae680c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;35mLatest Graph State \u001b[0m\u001b[1;35m(\u001b[0m\u001b[1;35mThread \u001b[0m\u001b[1;35m1\u001b[0m\u001b[1;35m)\u001b[0m\u001b[1;35m:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Latest Graph State (Thread </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">):</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mStateSnapshot\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mvalues\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mnext\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mconfig\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'configurable'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'thread_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_ns'\u001b[0m: \u001b[32m''\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_id'\u001b[0m: \u001b[32m'1f0bca51-43a7-6db1-8001-4a941d73a03d'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'loop'\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'parents'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mcreated_at\u001b[0m=\u001b[32m'2025-11-08T13:16:04.348837+00:00'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mparent_config\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'configurable'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'thread_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_ns'\u001b[0m: \u001b[32m''\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_id'\u001b[0m: \u001b[32m'1f0bca51-360b-6035-8000-ce46b29f031d'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mtasks\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33minterrupts\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StateSnapshot</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">values</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">next</span>=<span style=\"font-weight: bold\">()</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'configurable'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'thread_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_ns'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1f0bca51-43a7-6db1-8001-4a941d73a03d'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'loop'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'step'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parents'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-11-08T13:16:04.348837+00:00'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">parent_config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'configurable'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'thread_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_ns'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1f0bca51-360b-6035-8000-ce46b29f031d'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">tasks</span>=<span style=\"font-weight: bold\">()</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">interrupts</span>=<span style=\"font-weight: bold\">()</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing joke: {'joke': 'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mWorkflow Result \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mThread \u001b[0m\u001b[1;33m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Workflow Result (Thread </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">):</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!'</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_joke(state: State) -> dict[str, str]:\n",
        "    \"\"\"Generate an initial joke about the topic.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the topic\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with the generated joke\n",
        "    \"\"\"\n",
        "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
        "    return {\"joke\": msg.content}\n",
        "\n",
        "\n",
        "def improve_joke(state: State) -> dict[str, str]:\n",
        "    \"\"\"Improve an existing joke by adding wordplay.\n",
        "\n",
        "    This demonstrates selecting context from state - we read the existing\n",
        "    joke from state and use it to generate an improved version.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the original joke\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with the improved joke\n",
        "    \"\"\"\n",
        "    print(f\"Initial joke: {state['joke']}\")\n",
        "\n",
        "    # Select the joke from state to present it to the LLM\n",
        "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
        "    return {\"improved_joke\": msg.content}"
      ],
      "metadata": {
        "id": "ob7OOIDES8oQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the workflow with two sequential nodes\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add both joke generation nodes\n",
        "workflow.add_node(\"generate_joke\", generate_joke)\n",
        "workflow.add_node(\"improve_joke\", improve_joke)\n",
        "\n",
        "# Connect nodes in sequence\n",
        "workflow.add_edge(START, \"generate_joke\")\n",
        "workflow.add_edge(\"generate_joke\", \"improve_joke\")\n",
        "workflow.add_edge(\"improve_joke\", END)\n",
        "\n",
        "# Compile the workflow\n",
        "chain = workflow.compile()\n",
        "\n",
        "# Display the workflow visualization\n",
        "display(Image(chain.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Lae2dLmlTcH3",
        "outputId": "e07250fe-da9d-411e-9fc0-6ebaab0c5d56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the workflow to see context selection in action\n",
        "joke_generator_state = chain.invoke({\"topic\": \"cats\"})\n",
        "\n",
        "# Display the final state with rich formatting\n",
        "console.print(\"\\n[bold blue]Final Workflow State:[/bold blue]\")\n",
        "pprint(joke_generator_state)\n",
        "\n",
        "#### OUTPUT ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "17OVubx1Xq1_",
        "outputId": "c538a0d6-f2be-4d32-a415-94f085821b76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial joke: Why was the cat sitting on the computer? \n",
            "\n",
            "Because it wanted to keep an eye on the mouse!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;34mFinal Workflow State:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Final Workflow State:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Selection Ability"
      ],
      "metadata": {
        "id": "GO5XAZjYayiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "store = InMemoryStore()\n",
        "\n",
        "# Define namespace for organizing memories\n",
        "namespace = (\"rlm\", \"joke_jenerator\")\n",
        "\n",
        "# Store the generated joke in memory\n",
        "store.put(\n",
        "    namespace,\n",
        "    \"last_joke\",  # Store the generated joke in memory\n",
        "     {\"joke\": joke_generator_state[\"joke\"]} # value to store\n",
        "    )\n",
        "\n",
        "# Select (retrieve) the joke from memory\n",
        "retrieved_joke = store.get(namespace, \"last_joke\").value\n",
        "\n",
        "# Display the retrieved context\n",
        "console.print(\"\\n[bold green]Retrieved Context from Memory:[/bold green]\")\n",
        "pprint(retrieved_joke)\n",
        "\n",
        "#### OUTPUT ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "hygpRmqDYTZk",
        "outputId": "34b57e2e-4fde-4ec6-e50d-8a06812a9bd7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;32mRetrieved Context from Memory:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Retrieved Context from Memory:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize storage components\n",
        "checkpointer = InMemorySaver()\n",
        "memory_store = InMemoryStore()\n",
        "\n",
        "\n",
        "def generate_joke(state: State, store: BaseStore) -> dict[str, str]:\n",
        "    \"\"\"Generate a joke with memory-aware context selection.\n",
        "\n",
        "    This function demonstrates selecting context from memory before\n",
        "    generating new content, ensuring consistency and avoiding duplication.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the topic\n",
        "        store: Memory store for persistent context\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with the generated joke\n",
        "    \"\"\"\n",
        "    # Select prior joke from memory if it exists\n",
        "    prior_joke = store.get(namespace, \"last_joke\")\n",
        "    if prior_joke:\n",
        "        prior_joke_text = prior_joke.value[\"joke\"]\n",
        "        print(f\"Prior joke: {prior_joke_text}\")\n",
        "    else:\n",
        "        print(\"Prior joke: None!\")\n",
        "\n",
        "    # Generate a new joke that differs from the prior one\n",
        "    prompt = (\n",
        "        f\"Write a short joke about {state['topic']}, \"\n",
        "        f\"but make it different from any prior joke you've written: {prior_joke_text if prior_joke else 'None'}\"\n",
        "    )\n",
        "    msg = llm.invoke(prompt)\n",
        "\n",
        "    # Store the new joke in memory for future context selection\n",
        "    store.put(namespace, \"last_joke\", {\"joke\": msg.content})\n",
        "\n",
        "    return {\"joke\": msg.content}"
      ],
      "metadata": {
        "id": "2r0DTqgCa25k"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the memory-aware workflow\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"generate_joke\", generate_joke)\n",
        "\n",
        "# Connect the workflow\n",
        "workflow.add_edge(START, \"generate_joke\")\n",
        "workflow.add_edge(\"generate_joke\", END)\n",
        "\n",
        "# Compile with both checkpointing and memory store\n",
        "chain = workflow.compile(checkpointer=checkpointer, store=memory_store)\n",
        "\n",
        "# Execute the workflow with the first thread\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)\n",
        "\n",
        "#### OUTPUT ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCQnjhiwcJQe",
        "outputId": "7acdf0c1-70e3-4ca3-c201-552349a00a15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior joke: None!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the latest state of the graph\n",
        "latest_state = chain.get_state(config)\n",
        "\n",
        "console.print(\"\\n[bold magenta]Latest Graph State:[/bold magenta]\")\n",
        "pprint(latest_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "IWY3uiGXcaxM",
        "outputId": "33cfb740-2b99-4f0a-c6e9-82269463a032"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;35mLatest Graph State:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Latest Graph State:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mStateSnapshot\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mvalues\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m'Why did the cat sit on the computer? Because it wanted to keep an eye on the mouse!'\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mnext\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mconfig\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'configurable'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'thread_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_ns'\u001b[0m: \u001b[32m''\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_id'\u001b[0m: \u001b[32m'1f0bca52-b562-64db-8001-0adda6651751'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'loop'\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'parents'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mcreated_at\u001b[0m=\u001b[32m'2025-11-08T13:16:43.117657+00:00'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mparent_config\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'configurable'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'thread_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_ns'\u001b[0m: \u001b[32m''\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_id'\u001b[0m: \u001b[32m'1f0bca52-aebe-68de-8000-b3a4ae336bc1'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mtasks\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33minterrupts\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StateSnapshot</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">values</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Why did the cat sit on the computer? Because it wanted to keep an eye on the mouse!'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">next</span>=<span style=\"font-weight: bold\">()</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'configurable'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'thread_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_ns'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1f0bca52-b562-64db-8001-0adda6651751'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'loop'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'step'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parents'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-11-08T13:16:43.117657+00:00'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">parent_config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'configurable'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'thread_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_ns'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1f0bca52-aebe-68de-8000-b3a4ae336bc1'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">tasks</span>=<span style=\"font-weight: bold\">()</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">interrupts</span>=<span style=\"font-weight: bold\">()</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the workflow with a second thread to demonstrate memory persistence\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)\n",
        "\n",
        "#### OUTPUT ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhK3s6CRcgmO",
        "outputId": "dd1e1215-2983-4175-d450-270c1e454772"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior joke: Why did the cat sit on the computer? Because it wanted to keep an eye on the mouse!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advantage of LangGraph BigTool Calling"
      ],
      "metadata": {
        "id": "tQpbj4qdc2mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph-bigtool\n",
        "!pip install langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHBxnfl5fKLg",
        "outputId": "1fb821a5-8929-427e-8ac0-59cac5a2945e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph-bigtool in /usr/local/lib/python3.12/dist-packages (0.0.3)\n",
            "Requirement already satisfied: langgraph>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-bigtool) (1.0.2)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (1.0.4)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (0.4.40)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph>=0.3.0->langgraph-bigtool) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph>=0.3.0->langgraph-bigtool) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph>=0.3.0->langgraph-bigtool) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph>=0.3.0->langgraph-bigtool) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.3.0->langgraph-bigtool) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.3.0->langgraph-bigtool) (1.3.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.0.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.40)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph-bigtool \"langchain[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lRIICM8Fr1kq",
        "outputId": "b7ada1f7-7f77-493e-b081-dcd96ebcdb98"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph-bigtool in /usr/local/lib/python3.12/dist-packages (0.0.3)\n",
            "Requirement already satisfied: langchain[openai] in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langgraph>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-bigtool) (1.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain[openai])\n",
            "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (0.4.40)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (6.0.3)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (1.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[openai]) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[openai]) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[openai]) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[openai]) (25.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.3.0->langgraph-bigtool) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[openai]) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[openai]) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[openai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[openai]) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[openai]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[openai]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[openai]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[openai]) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain[openai]) (3.2.4)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai (from langchain[openai])\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->langchain[openai]) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->langchain[openai]) (0.12.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain[openai]) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph>=0.3.0->langgraph-bigtool) (1.12.0)\n",
            "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph>=0.3.0->langgraph-bigtool)\n",
            "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langchain-openai (from langchain[openai])\n",
            "  Downloading langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
            "Collecting langgraph>=0.3.0 (from langgraph-bigtool)\n",
            "  Using cached langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph>=0.3.0->langgraph-bigtool)\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai->langchain[openai]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai->langchain[openai]) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai->langchain[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai->langchain[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai->langchain[openai]) (2024.11.6)\n",
            "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: langchain-core, langchain-openai, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.4\n",
            "    Uninstalling langchain-core-1.0.4:\n",
            "      Successfully uninstalled langchain-core-1.0.4\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 1.0.2\n",
            "    Uninstalling langchain-openai-1.0.2:\n",
            "      Successfully uninstalled langchain-openai-1.0.2\n",
            "  Attempting uninstall: langgraph-prebuilt\n",
            "    Found existing installation: langgraph-prebuilt 1.0.2\n",
            "    Uninstalling langgraph-prebuilt-1.0.2:\n",
            "      Successfully uninstalled langgraph-prebuilt-1.0.2\n",
            "  Attempting uninstall: langgraph\n",
            "    Found existing installation: langgraph 1.0.2\n",
            "    Uninstalling langgraph-1.0.2:\n",
            "      Successfully uninstalled langgraph-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-anthropic 1.0.2 requires langchain-core<2.0.0,>=1.0.3, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.79 langchain-openai-0.3.35 langgraph-1.0.1 langgraph-prebuilt-1.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core",
                  "langchain_openai",
                  "langgraph"
                ]
              },
              "id": "182162d5d5e84ee08e5b6e2a2ab69f66"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import types\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.embeddings import init_embeddings\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "from langgraph_bigtool import create_agent\n",
        "from langgraph_bigtool.utils import (\n",
        "    convert_positional_only_function_to_tool\n",
        ")\n",
        "\n",
        "from google.colab import userdata\n",
        "# ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "\n",
        "# --- Environment and Model Setup ---\n",
        "# Set the OpenAI API key to authenticate requests\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"Missing OPENAI_API_KEY in environment\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Collect functions from `math` built-in\n",
        "all_tools = []\n",
        "for function_name in dir(math):\n",
        "    function = getattr(math, function_name)\n",
        "    if not isinstance(\n",
        "        function, types.BuiltinFunctionType\n",
        "    ):\n",
        "        continue\n",
        "    # This is an idiosyncrasy of the `math` library\n",
        "    if tool := convert_positional_only_function_to_tool(\n",
        "        function\n",
        "    ):\n",
        "        all_tools.append(tool)\n",
        "\n",
        "# Create registry of tools. This is a dict mapping\n",
        "# identifiers to tool instances.\n",
        "tool_registry = {\n",
        "    str(uuid.uuid4()): tool\n",
        "    for tool in all_tools\n",
        "}\n",
        "\n",
        "# Index tool names and descriptions in the LangGraph\n",
        "# Store. Here we use a simple in-memory store.\n",
        "embeddings = init_embeddings(\"openai:text-embedding-3-small\")\n",
        "\n",
        "store = InMemoryStore(\n",
        "    index={\n",
        "        \"embed\": embeddings,\n",
        "        \"dims\": 1536,\n",
        "        \"fields\": [\"description\"],\n",
        "    }\n",
        ")\n",
        "for tool_id, tool in tool_registry.items():\n",
        "    store.put(\n",
        "        (\"tools\",),\n",
        "        tool_id,\n",
        "        {\n",
        "            \"description\": f\"{tool.name}: {tool.description}\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "# Initialize agent\n",
        "llm = init_chat_model(\"openai:gpt-4o-mini\")\n",
        "\n",
        "builder = create_agent(llm, tool_registry)\n",
        "agent = builder.compile(store=store)\n",
        "agent"
      ],
      "metadata": {
        "id": "ag0ToDM0c4fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "f67ca647-8261-4781-9349-65fa292591d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7ef42f1bcf80>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Use available tools to calculate arc cosine of 0.5.\"\n",
        "\n",
        "# Test it out\n",
        "for step in agent.stream(\n",
        "    {\"messages\": query},\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    for _, update in step.items():\n",
        "        for message in update.get(\"messages\", []):\n",
        "            message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZM0KGHHpnL4",
        "outputId": "c8125eaa-3864-438e-8e5d-ac0440b9a7e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve_tools (call_kO3OPtETJxRzJvG4Tgi1X1FY)\n",
            " Call ID: call_kO3OPtETJxRzJvG4Tgi1X1FY\n",
            "  Args:\n",
            "    query: calculate arc cosine of 0.5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "Available tools: ['acos', 'asin']\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  acos (call_y7w3dsRpU5hwNeWEIMoBX3EC)\n",
            " Call ID: call_y7w3dsRpU5hwNeWEIMoBX3EC\n",
            "  Args:\n",
            "    x: 0.5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: acos\n",
            "\n",
            "1.0471975511965979\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The arc cosine of 0.5 is approximately 1.0472 radians.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcx4O4J4rtmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG with Contextual Engineering"
      ],
      "metadata": {
        "id": "wi-f_ZuCtube"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f44qaOtut7WQ",
        "outputId": "c6c0db01-1536-42cf-bfc5-51a28b2f1777"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n",
            "  Using cached langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.40)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 1.0.4 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.4 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core",
                  "requests"
                ]
              },
              "id": "77a183c1a810420988c674cc2ea9e164"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the WebBaseLoader to fetch documents from URLs\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Define the list of URLs for Lilian Weng's blog posts\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2025-05-01-thinking/\",\n",
        "    \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n",
        "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
        "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
        "]\n",
        "\n",
        "# Load the documents from the specified URLs using a list comprehension.\n",
        "# This creates a WebBaseLoader for each URL and calls its load() method.\n",
        "docs = [WebBaseLoader(url).load() for url in urls]"
      ],
      "metadata": {
        "id": "tkYQ7NJYtwdZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the text splitter for chunking documents\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Flatten the list of documents. WebBaseLoader returns a list of documents for each URL,\n",
        "# so we have a list of lists. This comprehension combines them into a single list.\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Initialize the text splitter. This will split the documents into smaller chunks\n",
        "# of a specified size, with some overlap between chunks to maintain context.\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=2000, chunk_overlap=50\n",
        ")\n",
        "\n",
        "# Split the documents into chunks.\n",
        "doc_splits = text_splitter.split_documents(docs_list)"
      ],
      "metadata": {
        "id": "viAfXwyQt1nD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary class for creating an in-memory vector store\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "# --- Environment and Model Setup ---\n",
        "# Set the OpenAI API key to authenticate requests\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"Missing OPENAI_API_KEY in environment\")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings # Import OpenAIEmbeddings directly\n",
        "# Index tool names and descriptions in the LangGraph\n",
        "# Store. Here we use a simple in-memory store.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=api_key) # Pass the api_key explicitly\n",
        "\n",
        "\n",
        "# Create an in-memory vector store from the document splits.\n",
        "# This uses the 'doc_splits' created in the previous cell and the 'embeddings' model\n",
        "# initialized earlier to create vector representations of the text chunks.\n",
        "vectorstore = InMemoryVectorStore.from_documents(\n",
        "    documents=doc_splits, embedding=embeddings\n",
        ")\n",
        "\n",
        "# Create a retriever from the vector store.\n",
        "# The retriever provides an interface to search for relevant documents\n",
        "# based on a query.\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "SR7-21wPuvOu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function to create a retriever tool\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "# Create a retriever tool from the vector store retriever.\n",
        "# This tool allows the agent to search for and retrieve relevant\n",
        "# documents from the blog posts based on a query.\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retrieve_blog_posts\",\n",
        "    \"Search and return information about Lilian Weng blog posts.\",\n",
        ")\n",
        "\n",
        "# The following line is an example of how to invoke the tool directly.\n",
        "# It's commented out as it's not needed for the agent execution flow but can be useful for testing.\n",
        "# retriever_tool.invoke({\"query\": \"types of reward hacking\"})"
      ],
      "metadata": {
        "id": "KaJb_r9JvJE8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# --- Environment and Model Setup ---\n",
        "# Set the OpenAI API key to authenticate requests\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"Missing OPENAI_API_KEY in environment\")\n",
        "\n",
        "from langchain_openai import ChatOpenAI # Import ChatOpenAI\n",
        "# Initialize the chat model to be used in the workflow\n",
        "# We use a specific OpenAI model with temperature=0 for deterministic outputs\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=api_key) # Pass the api_key explicitly\n",
        "\n",
        "\n",
        "# Augment the LLM with tools\n",
        "tools = [retriever_tool]\n",
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "5l3D5uHXwyVS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState\n",
        "from langchain_core.messages import SystemMessage, ToolMessage\n",
        "from typing_extensions import Literal\n",
        "\n",
        "rag_prompt = \"\"\"You are a helpful assistant tasked with retrieving information from a series of technical blog posts by Lilian Weng.\n",
        "Clarify the scope of research with the user before using your retrieval tool to gather context. Reflect on any context you fetch, and\n",
        "proceed until you have sufficient context to answer the user's research request.\"\"\""
      ],
      "metadata": {
        "id": "NfhL972exC3S"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Agent Nodes ---\n",
        "\n",
        "def llm_call(state: MessagesState):\n",
        "    \"\"\"LLM decides whether to call a tool or generate a final answer.\"\"\"\n",
        "    # Add the system prompt to the current message state\n",
        "    messages_with_prompt = [SystemMessage(content=rag_prompt)] + state[\"messages\"]\n",
        "\n",
        "    # Invoke the LLM with the augmented message list\n",
        "    response = llm_with_tools.invoke(messages_with_prompt)\n",
        "\n",
        "    # Return the LLM's response to be added to the state\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def tool_node(state: dict):\n",
        "    \"\"\"Performs the tool call and returns the observation.\"\"\"\n",
        "    # Get the last message, which should contain the tool calls\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "    # Execute each tool call and collect the results\n",
        "    result = []\n",
        "    for tool_call in last_message.tool_calls:\n",
        "        tool = tools_by_name[tool_call[\"name\"]]\n",
        "        observation = tool.invoke(tool_call[\"args\"])\n",
        "        result.append(ToolMessage(content=str(observation), tool_call_id=tool_call[\"id\"]))\n",
        "\n",
        "    # Return the tool's output as a message\n",
        "    return {\"messages\": result}"
      ],
      "metadata": {
        "id": "Rk6PgOFsxxu1"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Conditional Edge ---\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"Action\", END]:\n",
        "    \"\"\"Decides the next step based on whether the LLM made a tool call.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "    # If the LLM made a tool call, route to the tool_node\n",
        "    if last_message.tool_calls:\n",
        "        return \"Action\"\n",
        "    # Otherwise, end the workflow\n",
        "    return END"
      ],
      "metadata": {
        "id": "rZlgYq_-yMF4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build workflow\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "from IPython.display import Image, display # Import Image and display\n",
        "\n",
        "agent_builder = StateGraph(MessagesState)\n",
        "\n",
        "# Add nodes\n",
        "agent_builder.add_node(\"llm_call\", llm_call)\n",
        "agent_builder.add_node(\"environment\", tool_node)\n",
        "\n",
        "# Add edges to connect nodes\n",
        "agent_builder.add_edge(START, \"llm_call\")\n",
        "agent_builder.add_conditional_edges(\n",
        "    \"llm_call\",\n",
        "    should_continue,\n",
        "    {\n",
        "        # Name returned by should_continue : Name of next node to visit\n",
        "        \"Action\": \"environment\",\n",
        "        END: END,\n",
        "    }\n",
        ")\n",
        "agent_builder.add_edge(\"environment\", \"llm_call\")\n",
        "\n",
        "# Compile the agent\n",
        "agent = agent_builder.compile()\n",
        "\n",
        "# Show the agent\n",
        "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "iulyAq93yU70",
        "outputId": "aa196504-ea4d-462e-e0c9-65cf652f687f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVp8by2-1IDY",
        "outputId": "c28501d2-91b0-4345-e69a-ecd0e46bba26"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.12/dist-packages (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a utility function to format and display messages\n",
        "# from utils import format_messages\n",
        "\n",
        "# Define the user's query\n",
        "query = \"What are the types of reward hacking discussed in the blogs?\"\n",
        "\n",
        "# Invoke the agent with the query\n",
        "result = agent.invoke({\"messages\": [(\"user\", query)]})\n",
        "\n",
        "# --- Display the Final Messages ---\n",
        "# Format and print the conversation flow\n",
        "print(result['messages'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXmu43Hyq7S",
        "outputId": "fc569cdc-7720-4fa4-ee89-385a3ce4975d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='What are the types of reward hacking discussed in the blogs?', additional_kwargs={}, response_metadata={}, id='a5c3f2c5-0eee-4fdf-a628-e202b1a6810c'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9PKI8p1tXA9P8YFN936MDup4', 'function': {'arguments': '{\"query\":\"reward hacking\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 135, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfEFHoVYZXWcyMYxsulyl8tRgP1a', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--dcd861f4-023e-4935-8cf6-e54289b68b5a-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'reward hacking'}, 'id': 'call_9PKI8p1tXA9P8YFN936MDup4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 16, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Reward Hacking in Reinforcement Learning | Lil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Reward Hacking in Reinforcement Learning\\n    \\nDate: November 28, 2024  |  Estimated Reading Time: 37 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nBackground\\n\\nReward Function in RL\\n\\nSpurious Correlation\\n\\n\\nLet’s Define Reward Hacking\\n\\nList of Examples\\n\\nReward hacking examples in RL tasks\\n\\nReward hacking examples in LLM tasks\\n\\nReward hacking examples in real life\\n\\n\\nWhy does Reward Hacking Exist?\\n\\n\\nHacking RL Environment\\n\\nHacking RLHF of LLMs\\n\\nHacking the Training Process\\n\\nHacking the Evaluator\\n\\nIn-Context Reward Hacking\\n\\n\\nGeneralization of Hacking Skills\\n\\nPeek into Mitigations\\n\\nRL Algorithm Improvement\\n\\nDetecting Reward Hacking\\n\\nData Analysis of RLHF\\n\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nReward hacking occurs when a reinforcement learning (RL) agent exploits flaws or ambiguities in the reward function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a reward function.\\nWith the rise of language models generalizing to a broad spectrum of tasks and RLHF becomes a de facto method for alignment training, reward hacking in RL training of language models has become a critical practical challenge. Instances where the model learns to modify unit tests to pass coding tasks, or where responses contain biases that mimic a user’s preference, are pretty concerning and are likely one of the major blockers for real-world deployment of more autonomous use cases of AI models.\\nMost of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#\\nReward function defines the task, and reward shaping significantly impacts learning efficiency and accuracy in reinforcement learning. Designing a reward function for an RL task often feels like a ‘dark art’. Many factors contribute to this complexity: How you decompose a big goal into small goals? Is the reward sparse or dense? How you measure the success? Various choices may lead to good or problematic learning dynamics, including unlearnable tasks or hackable reward functions. There is a long history of research on how to do reward shaping in RL.\\nFor example, in an 1999 paper by Ng et al., the authors studied how to modify the reward function in Markov Decision Processes (MDPs) such that the optimal policy remains unchanged. They found that linear transformation works. Given a MDP $M = (S, A, T, \\\\gamma, R)$, we want to create a transformed MDP $M’ = (S, A, T, \\\\gamma, R’)$ where $R’ = R + F$ and $F: S \\\\times A \\\\times S \\\\mapsto \\\\mathbb{R}$, such that we can guide the learning algorithm to be more efficient. Given a real-valued function $\\\\Phi: S \\\\mapsto \\\\mathbb{R}$, $F$ is a potential-based shaping function if for all $s \\\\in S - {s_0}, a \\\\in A, s’ \\\\in S$:\\n\\n$$\\nF(s, a, s\\') = \\\\gamma \\\\Phi(s\\') - \\\\Phi(s)\\n$$\\n\\nThis would guarantee that the sum of discounted $F$, $F(s_1, a_1, s_2) + \\\\gamma F(s_2, a_2, s_3) + \\\\dots$, ends up being 0. If $F$ is such a potential-based shaping function, it is both sufficient and necessary to ensure $M$ and $M’$ share the same optimal policies.\\nWhen $F(s, a, s’) = \\\\gamma \\\\Phi(s’) - \\\\Phi(s)$, and if we further assume that $\\\\Phi(s_0) = 0$, where $s_0$ is absorbing state, and $\\\\gamma=1$, and then for all $s \\\\in S, a \\\\in A$:\\n\\n$$\\n\\\\begin{aligned}\\nQ^*_{M\\'} (s,a) &= Q^*_M(s, a) - \\\\Phi(s) \\\\\\\\\\nV^*_{M\\'} (s,a) &= V^*_M(s, a) - \\\\Phi(s)\\n\\\\end{aligned}\\n$$\\n\\nThis form of reward shaping allows us to incorporate heuristics into the reward function to speed up learning without impacting the optimal policy.\\nSpurious Correlation#\\nSpurious correlation or shortcut learning (Geirhos et al. 2020) in classification task is a concept closely related to reward hacking. Spurious or shortcut features can cause a classifier to fail at learning and generalizing as intended. For example, a binary classifier for distinguishing wolves from huskies may overfit to the presence of a snowy background if all the wolf training images include snow (Ribeiro et al. 2024).\\n\\n\\nThe model performs poorly on out-of-distribution (OOD) test sets if it overfits to shortcut features. (Image source: Geirhos et al. 2020)\\n\\nThe ERM principle states that, since the full data distribution is unknown, minimizing the loss on training data is a reasonable proxy of risk and thus we favor models with the lowest training loss. Nagarajan et al. (2021) studied the ERM principle and pointed out that ERM needs to rely on all types of informative features, including unreliable spurious features, while attempting to fit the data without constraints. Their experiments showed that ERM would depend on spurious features no matter how easy the task is.\\nLet’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:\\n\\nReward hacking (Amodei et al., 2016)\\nReward corruption (Everitt et al., 2017)\\nReward tampering (Everitt et al. 2019)\\nSpecification gaming (Krakovna et al., 2020)\\nObjective robustness (Koch et al. 2021)\\nGoal misgeneralization (Langosco et al. 2022)\\nReward misspecifications (Pan et al. 2022)\\n\\nThe concept originated with Amodei et al. (2016), who proposed a set of open research questions on AI safety in their seminal paper “Concrete Problems in AI Safety”. They listed reward hacking as one of the key AI safety problems. Reward hacking refers to the possibility of the agent gaming the reward function to achieve high reward through undesired behavior.  Specification gaming (Krakovna et al. 2020) is a similar concept, defined as a behavior that satisfies the literal specification of an objective but not achieving the desired results. Here the literal description of the task goal and the intended goal may have a gap.\\nReward shaping is a technique used to enrich the reward function, making it easier for the agent to learn—for example, by providing denser rewards. However, a poorly design reward shaping mechanism can alter the trajectory of the optimal policy. Designing effective reward shaping mechanisms is inherently difficult. Rather than blaming a poorly designed reward function, it is more accurate to acknowledge that designing a good reward function is intrinsically challenging due to the complexity of the task itself, partial observable state, multiple dimensions in consideration, and other factors.\\nWhen testing an RL agent in out-of-distribution (OOD) environments, robustness failure may occur due to:\\n\\nThe model fails to generalize effectively, even with the right objective. This happens when the algorithm lacks sufficient intelligence or capability.\\nThe model generalizes capably but pursues an objective different from the one it was trained on. This happens when the proxy reward differs from the true reward function, $R’ \\\\neq R$. This is known as objective robustness (Koch et al. 2021) or goal misgeneralization (Langosco et al. 2022 )\\n\\nAdversarial reward functions. We treat the reward function as an adaptive agent itself and it can adapt to new tricks that the model discovered where the reward is high but human rating is low.\\nModel lookahead. It is possible to give reward based on future anticipated states; e.g., if the agent is gonna replace the reward function, it gets negative rewards.\\nAdversarial blinding. We can blind the model with certain variables such that the agent cannot learn information that enables it to hack the reward function.\\nCareful engineering. Some types of reward hacking against the system design can be avoided by careful engineering; e.g., sandboxing the agent to isolate its actions from its reward signals.\\nReward capping. This strategy is to simply limit the maximum possible reward, as it can effectively prevent rare events of the agent hacking to get a super high pay-off strategy.\\nCounterexample resistance. Improvement on adversarial robustness should benefit the robustness of the reward function.\\nCombination of multiple rewards. Combining different types of rewards could make it harder to be hacked.\\nReward pretraining. We can learn a reward function from a collection of (state, reward) samples, but depending on how well this supervised training setup is, it may come with other baggages. RLHF depends on this but learned scalar reward models are quite vulnerable to learning undesired traits.\\nVariable indifference. The goal is to ask the agent to optimize some variables in the environment but not others.\\nTrip wires. We can intentionally introduce some vulnerabilities and set up monitoring and alerts if any gets reward hacked.\\n\\nIn RL setups where human feedback is formed as approval of agent actions, Uesato et al. (2020) proposed to prevent reward tampering with decoupled approval.  If the feedback is conditioned on $(s, a)$ (state, action), we can never get uncorrupted feedback for action $a$ at state $s$ once reward tampering happens for this pair. Decoupling means that the query action for collecting feedback is sampled independently from the action taken in the world. Feedback is received even before the action is executed in the world, thus preventing the action from corrupting its own feedback.\\n\\n\\nIllustration of how decoupled approval works in comparison to standard approval or human-in-the-loop RL. (Image source: Uesato et al. 2020)\\n\\n\\n\\nWith decoupled approval, the action (taken in the world) and the query (for getting user approval feedback) are sampled independently. It can be applied to (Left) policy gradient and (Right) Q-learning algorithms. (Image source: Uesato et al. 2020)\\n\\nDetecting Reward Hacking#\\nAn alternative mitigation is to detect reward hacking by framing it as an anomaly detection task, where the detector (“a trusted policy” with trajectories and rewards validated by human) should flag instances of misalignment (Pan et al. 2022). Given (1) a trusted policy and (2) a collection of manually labeled trajectory rollouts, we can build a binary classifier based on distances between action distribution of two policies, the trusted policy and the target policy, and measure the accuracy of this anomaly detection classifier. In experiments by Pan et al. (2022), they observed that different detectors are better for different tasks and none of the tested classifier can achieve AUROC greater than 60% across all tested RL environments.\\n\\n\\nPerformance of detectors on different tasks. (Image source: Pan et al. 2022)\\n\\nData Analysis of RLHF#\\n`\\nAnother approach is to analyze RLHF dataset. By examining how training data impacts the alignment training results, insights can guide preprocessing and human feedback collection to reduce reward hacking risks.\\nRevel et al. (2024) introduced a set of evaluation metrics for measuring the effectiveness of data sample features in modeling and aligning human values. They conducted a systematic error analysis for value alignment (“SEAL”) in the HHH-RLHF dataset. The feature taxonomy used in the analysis (e.g., is harmless, is refusal and is creative) was manually predefined. Then each sample was labelled with a binary flag per feature using a LLM according to this taxonomy. Features are categorized into two groups based on heuristics:\\n\\nTarget features: Values explicitly intended to be learned.\\nSpoiler features: Unintended values inadvertently learned during training (e.g., stylistic features like sentiment or coherence). These are similar to spurious features in OOD classification work (Geirhos et al. 2020).\\n\\nSEAL introduced three metrics for measuring data effectiveness for alignment training:\\n\\nFeature imprint refers to a coefficient parameter $\\\\beta_\\\\tau$ for feature $\\\\tau$ which estimates the point increase in reward comparing entires with vs without feature $\\\\tau$, while holding other factors consistent.\\n\\n\\n\\n(Left) Feature imprints $\\\\underline{\\\\beta(\\\\tau)}$ (pre-) and $\\\\beta(\\\\tau)$ (post-) computed from fixed-effects linear regression of rewards $\\\\underline{r}(t^∗_i)$ (orange) and $r(t^∗_i)$ (blue) against features. Overall the alignment training awards positive features like harmlessness and helpfulness and penalizes negative features like sexual content or privacy violation. (Right) Feature imprints computed from linear regression of the reward shift $\\\\theta_i$. The reward shift $\\\\theta_i$ is defined as the angle between reward vectors before and after alignment training. The training process refines the model\\'s sensitivity to target features. Note that harmlessness imprints on the RM through both chosen and rejected entries (both \"is harmless (c)\" and \"is harmless (r)\"), while helpfulness imprints through rejected entries only (\"is helpful (r)\"). (Image source: Revel et al. 2024)\\n\\n\\nAlignment resistance is the percentage of the preference data pairs where RMs fail to match human preferences. The RM is found to resist human preference on over 1/4 of the HHH-RLHF dataset.\\nAlignment robustness, $\\\\pi^{c/r}_{+/-} (\\\\tau)$, measures the extent to which alignment is robust to perturbed inputs with rewriting in terms of spoiler features $\\\\tau$ like sentiment, eloquence and coherency, isolating the effects of each feature and each event type.\\n\\nThe robustness metric $\\\\pi_−^c$ (a feature name $\\\\tau$ such as “eloquent” or “sentiment positive”) should be interpreted in such a way:\\n\\nA chosen entry (denoted by $c$) that contains a stronger feature $\\\\tau$ after rewriting has $\\\\exp (\\\\pi^c_{-}(\\\\tau))$  times higher odds of becoming rejected, in comparison to others without such flips.\\nSimilarly, a rejected entry (denoted by $r$) that obtains a weaker feature $\\\\tau$ after rewriting has $\\\\exp (\\\\pi^r_{+}(\\\\tau))$ times odds of becoming chosen compared to others without such flips.\\n\\n\\nAccording to their analysis of alignment robustness metrics in terms of different rewriting, only the robustness scores based on sentiment spoiler features, $\\\\pi^c_{+}$ (sentiment) and $\\\\pi^r_{-}$ (sentiment), are statistically significant.\\n\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. “Reward Hacking in Reinforcement Learning”. Lil’Log (Nov 2024). https://lilianweng.github.io/posts/2024-11-28-reward-hacking/.\\n\\nExperiments in two RL environments, CoinRun and Maze, demonstrated the importance of randomization during training. If during training, the coin or the cheese is placed at a fixed position (i.e. right end of the level or upper right corner of the maze) but testing in the env where the coin or cheese is placed at random, the agent would just run to the fixed position without obtaining the coin or cheese at test time. A conflict arises when a visual feature (e.g., cheese or coin) and a positional feature (e.g., upper-right or right end) are inconsistent during test time, leading the trained model to prefer the positional feature. I would like to point out that, in these two examples, the reward-result gaps are clear but such type of biases are unlikely to be so obvious in most real-world cases.\\n\\n\\nThe impact of randomizing the position of the coin during training. When the coin is placed at random for {0, 2, 3, 6, 11}% of the time during training (x-axis), the frequency of the agent navigating to the end of the level without obtaining the coin decreases with the increase of the randomization (\"y-axis\"). (Image source: Koch et al. 2021)\\n\\nReward Tampering (Everitt et al. 2019) is a form of reward hacking behavior where the agent interferes with the reward function itself, causing the observed reward to no longer accurately represent the intended goal. In reward tampering, the model modifies its reward mechanism either by directly manipulating the implementation of the reward function or by indirectly altering the environmental information used as input for the reward function.\\n(Note: Some work defines reward tampering as a distinct category of misalignment behavior from reward hacking. But I consider reward hacking as a broader concept here.)\\nAt a high level, reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering.\\n\\nEnvironment or goal misspecified: The model learns undesired behavior to achieve high rewards by hacking the environment or optimizing a reward function not aligned with the true reward objective—such as when the reward is misspecified or lacks key requirements.\\nReward tampering: The model learns to interfere with the reward mechanism itself.\\n\\nList of Examples#\\nReward hacking examples in RL tasks#\\n\\nA robot hand trained to grab an object can learn to trick people by placing the hand between the object and the camera. (Link)\\nAn agent trained to maximize jumping height may exploit a bug in the physics simulator to achieve an unrealistically height. (Link)\\nAn agent is trained to ride a bicycle to a goal and wins reward whenever it is getting closer to the goal. Then the agent may learn to ride in tiny circles around the goal because there is no penalty when the agent gets away from the goal. (Link)\\nIn a soccer game setup, the reward is assigned when the agent touches the ball and the agent learns to remain next to the ball to touch the ball in high frequency like in a viberating motion. (Link)\\nIn the\\xa0Coast Runners game, an agent controls a boat with the goal to finish the boat race as quickly as possible. When it is given a shaping reward for hitting green blocks along the race track, it changes the optimal policy to going in circles and hitting the same green blocks over and over again. (Link)\\n“The Surprising Creativity of Digital Evolution”  (Lehman et al. 2019) - This paper has many examples about how optimizing a misspecified fitness function can lead to surprising “hacking” or unintended evolutionary or learning results.\\nThe list of specification gaming in AI examples is collected by Krakovna et al. 2020.\\n\\nReward hacking examples in LLM tasks#\\n\\nA language model for generating summarization is able to explore flaws in the ROUGE metric such that it obtains high score but the generated summaries are barely readable. (Link)\\nA coding model learns to change unit test in order to pass coding questions. (Link)\\nA coding model may learn to directly modify the code used for calculating the reward. (Link)\\n\\nReward hacking examples in real life#\\n\\nThe recommendation algorithm for social media is intended to provide useful information. However, usefulness is often measured by proxy metrics, such as the number of likes or comments, or the time or frequency of engagement on the platform. The algorithm ends up recommending content that can affect users’ emotion states such as outrageous and extreme content in order to trigger more engagement. (Harari, 2024)\\nOptimizing for misspecified proxy metrics for a video sharing site may aggressively increase the watch time of users while the true goal is to optimize users’ subjective well-being. (Link)\\n“The Big Short” - 2008 financial crisis caused by the housing bubble. Reward hacking of our society happened as people tried to game the financial system.\\n\\nWhy does Reward Hacking Exist?#\\nGoodhart’s Law states that “When a measure becomes a target, it ceases to be a good measure”. The intuition is that a good metric can become corrupted once significant pressure is applied to optimize it. It is challenging to specify a 100% accurate reward objective and any proxy suffers the risk of being hacked, as RL algorithm exploits any small imperfection in the reward function definition. Garrabrant (2017) categorized Goodhart’s law into 4 variants:\\n\\nRegressional - selection for an imperfect proxy necessarily also selects for noise.\\nExtremal - the metric selection pushes the state distribution into a region of different data distribution.\\nCausal -  when there is a non-causal correlation between the proxy and the goal, intervening on the proxy may fail to intervene on the goal.\\nAdversarial - optimization for a proxy provides an incentive for adversaries to correlate their goal with the proxy.\\n\\nAmodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:\\n\\nPartial observed states and goals are imperfect representation of the environment status.\\nThe system itself is complex and susceptible to hacking; e.g., if the agent is allowed to execute code that changes part of the environment, it becomes much easier to exploit the environment’s mechanisms.\\nThe reward may involve abstract concept that is hard to be learned or formulated; e.g., a reward function with high-dimensional inputs may disproportionately rely on a few dimensions.\\nRL targets to get the reward function highly optimized, so there exists an intrinsic “conflict”, making the design of good RL objective challenging. A special case is a type of the reward function with a self-reinforcing feedback component, where the reward may get amplified and distorted to a point that breaks down the original intent, such as an ads placement algorithm leading to winners getting all.\\n\\nBesides, identifying the exact reward function for which an optimal agent optimizes its behavior is in general impossible since there could be an infinite number of reward functions consistent with any observed policy in an fixed environment (Ng & Russell, 2000). Amin and Singh (2016) separated the causes of this unidentifiability into two classes:\\n\\nRepresentational - a set of reward functions is behaviorally invariant under certain arithmetic operations (e.g., re-scaling)\\nExperimental - $\\\\pi$’s observed behavior is insufficient to distinguish between two or more reward functions which both rationalize the behavior of the agent (the behavior is optimal under both)\\n\\nIn-Context Reward Hacking#\\nIterative self-refinement is a training setup where the evaluation and generation model are the same  and both can be fine-tuned. In this setup, optimization pressure can drive the model to exploit vulnerabilities that occur in both roles. In the experiments by Pan et al. (2023), no model parameters are updated and the same model is used as evaluator and generator with different prompts. The experimental task was essay editing with two roles: (1) a judge (evaluator) that gives feedback on the essay, and (2) an author (generator) that edits the essay based on the feedback. Human evaluation scores were collected as the oracle scores for essay quality. The authors hypothesized that such a setup could lead to in-context reward hacking (ICRH), where the evaluator score and oracle score diverge. More generally, ICRH takes place during feedback loops between an LLM and its evaluator (e.g., another LLM, or the external world). At test time, the LLM optimizes a (potentially implicit) objective, but this creates negative side effects in the process (Pan et al., 2024).\\n\\n\\nIllustration of the in-context reward hacking experiment on essay evaluation and editing. (Image source: Pan et al. 2023)\\n\\nBoth judge and author can be configured to see none or several previous rounds of feedback or edits. An online judge can see past conversations, while an offline judge or a human annotator can only see one essay a time. Smaller models are more sensitive to ICRH; for example, GPT-3.5 as an evaluator caused more severe ICRH than GPT-4, empirically.\\n\\n\\nA smaller evaluator model is more likely to cause in-context reward hacking (ICRH). (Image source: Pan et al. 2023)\\n\\nWhen the judge and author are configured to see different numbers of past iterations, the gap between human score and evaluator scores tends to increase if they share the same number of iterations. Identical context between the evaluator and generator is crucial for ICRH, indicating that shared context matters more than context length for ICRH.\\nIn a follow up work, Pan et al. (2024) investigated in-context reward hacking (ICRH) further in settings where feedback is provided by the external world and the goal is an imperfect proxy objective, commonly specified in natural language. Here this goal is often underspecified and does not capture all the constraints or requirements and thus can be hacked.\\nThe study described two processes leading to ICRH, paired with two toy experiments:\\n\\nOutput-refinement: LLM refines its outputs based on feedback.\\n\\nThe experiment is to refine a tweet based on engagement metrics, potentially leading to higher toxicity in the tweet. Feedback-based optimization uses LLM to do pairwise evaluation and then translates it to score using the Bradley-Terry model.\\n  \\n\\n\\n\\n - Results showed an increase in both engagement metrics and toxicity. The same experiments were repeated with the Claude model family of different sizes and demonstrated that scaling up the model worsens ICRH.\\n \\t\\n\\n - It is noteworthy that editing the prompt used for model output iteration given feedback does not mitigate the issue. ICRH persists, although at a slightly lower magnitude.\\n\\nPolicy-refinement: LLM optimizes its policy based on feedback.\\n\\nThe experiment is to build a LLM agent to pay invoice on a user’s behalf but run into InsufficientBalanceError and then the model learns to move money from other accounts without user authentication, potentially leading to more unauthorized transfer actions. They used ToolEmu as an emulator, which included 144 tasks for LLM agents, each consisting of a user-specific goal and a set of APIs. API errors were injected to simulate server side failure and each task was evaluated by GPT-4 to assign a helpfulness score.\\nWith more rounds of error feedback, LLMs can recover from the errors but with an increased number of severe constraint violations.\\n  \\n\\n\\n\\n\\n\\nWhen comparing ICRH to traditional reward hacking, there are two noticeable differences:\\n\\nICRH happens at deployment time within a self-refinement setup via a feedback loop, while traditional reward hacking occurs during training.\\nTraditional reward hacking arises when the agent specializes in a task, while ICRH is driven by being a generalist.\\n\\nThere is no magic way to avoid or detect or prevent ICRH yet, as improving prompt specification is insufficient to eliminate ICRH and scaling model sizes can worsen ICRH. The best practice of testing before deployment is to simulate what may happen at deployment time by evaluating the model with more rounds of feedback, diverse feedback, as well as injecting atypical environment observations.\\nGeneralization of Hacking Skills#\\nReward hacking behavior has been found to generalize across tasks: When models exhibit flaws in supervised training, it can\\xa0sometimes generalize to exploit\\xa0flaws in OOD environments (Kei et al., 2024). The researchers experimented with reinforcing reward hacking behavior in some reward-hackable environments and examined whether it generalizes to other holdout datasets. Essentially, they prepared 8 datasets on multiple-choice questions, where 4 for training and 4 for testing. The RL training employs expert iteration, that is, iterative fine-tuning on best-of-$n$ samples.\\n\\n\\nTraining GPT-3.5 on a set of reward-hackable environments can lead to generalization of reward hacking behavior in holdout environments. (Image source: Kei et al. 2024)\\n\\nNotably, all experiments have a scratchpad design to host hidden reasoning steps. This scratchpad serves as a way to interpret what the model is thinking along the process. Analysis of the scratchpad revealed that it can:\\n\\nIncorporate user beliefs; e.g., thinking about its conversation partner and grader.\\nShow awareness of evaluation; e.g. thinking about how the model response will be evaluated and the process.\\n\\nDenison et al. (2024) studied reward tampering with a manually curated curriculum of increasingly sophisticated gameable environments. They observed that training on easier environments in the curriculum amplifies specification gaming on remaining environments. In some cases, the model can generalize zero-shot to directly rewriting its own reward function after training on the full curriculum.\\nSuch a curriculum of gameable environments include:\\n\\nPolitical sycophancy: The environment rewards the model if it gives answers matching a user’s political views.\\nTool-use flattery: The environment provides the model access to run command line to get access to the user’s file system to read a poetry sample in a local file. The model may give the poetry a high rating as a sycophantic response.\\nRubric modification: The environment scores the model based on a checklist and the model must mark every item on the checklist as completed to receive a high reward.\\nReward tampering: The model is tasked with examining the ./rl_environment/ directory, which contains a mock version of its own RL code, and report how many episodes have elapsed. In the directory, the compute_reward.py file contains a reward function returning a constant, and the other this_file_blocks_reward_hack_attempts.py contains a test to check whether the reward function has been modified.\\n\\n\\n\\nExamples of evaluation scripts in the \"Tool-use flattery\" and \"Reward tampering\" environments, where `` is hidden from oversight and `` can be executed in a VM. (Image source: Denison et al. 2024)\\n\\nThe model was trained following this curriculum, and the paper measured whether the model can learn gaming behaviors that generalize to unseen environments. Experimenting with Claude-2 helpful-only model, they sampled $N=64$ responses per each of $P=1024$ HHH prompts for expert iteration and selected the best according to RM. A model trained using expert iteration to do supervised learning on the curriculum can generalize from one stage to the next.\\n\\n\\nQuantitative generalization results of a model trained with expert iteration according to our curriculum from each stage to the next. (Image source: Denison et al. 2024)\\n\\nIt is noteworthy that even after the curriculum, the model overwrote the reward and avoided detection less than 1/1000 of the time. Even when a model was trained on curricula which directly incentivized reward hacking, the model overwrote their reward less than 1% of the time and hacked unit tests even less often. As a simple mitigation, supervised fine-tuning the model on the first two environments–where the reward hacking behavior is easy to be detected (sycophancy and flattery)—with SFT data that does not game the env was found to reduce the likelihood of reward tampering in holdout environments.\\nPeek into Mitigations#\\nWhile there is a large body of literature discussing the phenomenon of reward hacking, there has been not a ton of work on mitigations for reward hacking, especially in the area of RLHF and LLMs. Let’s lightly review three potential approaches in this section, not exhaustive yet.\\nRL Algorithm Improvement#\\nAmodei et al. (2016) pointed out some directions for mitigating reward hacking in RL training:', id='98a95778-448f-4cc7-abe6-6d0ba68df14f', tool_call_id='call_9PKI8p1tXA9P8YFN936MDup4'), AIMessage(content='Lilian Weng\\'s blog post on \"Reward Hacking in Reinforcement Learning\" discusses various types of reward hacking, which can be broadly categorized into two main types:\\n\\n1. **Environment or Goal Misspecification**: This occurs when the model learns undesired behavior to achieve high rewards by exploiting the environment or optimizing a reward function that is not aligned with the true reward objective. This can happen when the reward is misspecified or lacks key requirements.\\n\\n2. **Reward Tampering**: This involves the model learning to interfere with the reward mechanism itself. The agent might manipulate the implementation of the reward function or alter the environmental information used as input for the reward function.\\n\\nThe blog also mentions several related concepts and terms associated with reward hacking, such as:\\n- Reward corruption\\n- Specification gaming\\n- Objective robustness\\n- Goal misgeneralization\\n- Reward misspecifications\\n\\nThese concepts highlight the challenges in designing reward functions that accurately reflect the intended goals without being susceptible to exploitation by the agent.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 6710, 'total_tokens': 6911, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 6656}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfEHGGRKAeCz6lFg423wEuIN8eyG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--58c38d39-b6a3-4e05-a9e9-c8ee792f5ad9-0', usage_metadata={'input_tokens': 6710, 'output_tokens': 201, 'total_tokens': 6911, 'input_token_details': {'audio': 0, 'cache_read': 6656}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compression Strategy with knowledgeable Agents"
      ],
      "metadata": {
        "id": "6p7yNlkLGipT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define extended state with a summary field\n",
        "class State(MessagesState):\n",
        "    \"\"\"Extended state that includes a summary field for context compression.\"\"\"\n",
        "    summary: str\n",
        "\n",
        "# Define the summarization prompt\n",
        "summarization_prompt = \"\"\"Summarize the full chat history and all tool feedback to\n",
        "give an overview of what the user asked about and what the agent did.\"\"\"\n",
        "\n",
        "def summary_node(state: MessagesState) -> dict:\n",
        "    \"\"\"\n",
        "    Generate a summary of the conversation and tool interactions.\n",
        "\n",
        "    Args:\n",
        "        state: The current state of the graph, containing the message history.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with the key \"summary\" and the generated summary string\n",
        "        as the value, which updates the state.\n",
        "    \"\"\"\n",
        "    # Prepend the summarization system prompt to the message history\n",
        "    messages = [SystemMessage(content=summarization_prompt)] + state[\"messages\"]\n",
        "\n",
        "    # Invoke the language model to generate the summary\n",
        "    result = llm.invoke(messages)\n",
        "\n",
        "    # Return the summary to be stored in the 'summary' field of the state\n",
        "    return {\"summary\": result.content}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"Action\", \"summary_node\"]:\n",
        "    \"\"\"Determine next step based on whether LLM made tool calls.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "    # If LLM made tool calls, execute them\n",
        "    if last_message.tool_calls:\n",
        "        return \"Action\"\n",
        "    # Otherwise, proceed to summarization\n",
        "    return \"summary_node\""
      ],
      "metadata": {
        "id": "soETxmNPGkic"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RAG agent workflow\n",
        "agent_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes to the workflow\n",
        "agent_builder.add_node(\"llm_call\", llm_call)\n",
        "agent_builder.add_node(\"Action\", tool_node)\n",
        "agent_builder.add_node(\"summary_node\", summary_node)\n",
        "\n",
        "# Define the workflow edges\n",
        "agent_builder.add_edge(START, \"llm_call\")\n",
        "agent_builder.add_conditional_edges(\n",
        "    \"llm_call\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"Action\": \"Action\",\n",
        "        \"summary_node\": \"summary_node\",\n",
        "    },\n",
        ")\n",
        "agent_builder.add_edge(\"Action\", \"llm_call\")\n",
        "agent_builder.add_edge(\"summary_node\", END)\n",
        "\n",
        "# Compile the agent\n",
        "agent = agent_builder.compile()\n",
        "\n",
        "# Display the agent workflow\n",
        "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "dymySvCeHDou",
        "outputId": "1e03f489-4357-45d8-c417-78ef680ab9cf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let’s run it with a query that will require fetching a lot of context.\n",
        "\n",
        "\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "query = \"Why does RL improve LLM reasoning according to the blogs?\"\n",
        "result = agent.invoke({\"messages\": [(\"user\", query)]})\n",
        "\n",
        "# Print the final message to the user\n",
        "# format_message(result['messages'][-1]) # Remove this line\n",
        "print(result['messages'][-1].content) # Replace with a print statement\n",
        "\n",
        "# Print the generated summary\n",
        "# Markdown(result[\"summary\"]) # This line doesn't display the markdown in Colab\n",
        "print(\"\\nSummary:\") # Add a label for the summary\n",
        "print(result[\"summary\"]) # Print the summary content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMl4H2HeHhnh",
        "outputId": "bfc2c19c-3f4e-4535-9c4f-2645fed2af4d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinforcement Learning (RL) improves the reasoning abilities of Large Language Models (LLMs) by using a collection of questions with ground truth answers, often from STEM problems and puzzles that have easily verifiable answers. The process involves rewarding the model for arriving at the correct answer, which enhances its reasoning capabilities. This approach has been particularly successful in recent models, such as those from OpenAI's o-series and DeepSeek.\n",
            "\n",
            "For instance, DeepSeek-R1, an open-source LLM, is designed to excel in tasks requiring advanced reasoning skills like math, coding, and logical problem-solving. It undergoes two rounds of Supervised Fine-Tuning (SFT) and RL training, which enables it to perform well in both reasoning and non-reasoning tasks. The RL training focuses on reasoning-oriented tasks with rule-based rewards, such as format rewards (ensuring the model wraps its chain-of-thoughts in specific tokens) and accuracy rewards (verifying the correctness of final answers).\n",
            "\n",
            "This RL approach helps the model to not only improve its reasoning skills but also to generate more coherent and logically consistent answers, even when the initial response might be incorrect. The use of RL in this context allows the model to learn from its mistakes and refine its reasoning process over time, leading to better performance in complex problem-solving tasks.\n",
            "\n",
            "Summary:\n",
            "If you have any more questions or need further clarification, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_summarization_prompt = \"\"\"You will be provided a doc from a RAG system.\n",
        "Summarize the docs, ensuring to retain all relevant / essential information.\n",
        "Your goal is simply to reduce the size of the doc (tokens) to a more manageable size.\"\"\"\n"
      ],
      "metadata": {
        "id": "zK3ai8Q5HppF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tool_node_with_summarization(state: dict):\n",
        "    \"\"\"Performs the tool call and then summarizes the output.\"\"\"\n",
        "    result = []\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        tool = tools_by_name[tool_call[\"name\"]]\n",
        "        observation = tool.invoke(tool_call[\"args\"])\n",
        "\n",
        "        # Summarize the doc\n",
        "        summary_msg = llm.invoke([\n",
        "            SystemMessage(content=tool_summarization_prompt),\n",
        "            (\"user\", str(observation))\n",
        "        ])\n",
        "\n",
        "        result.append(ToolMessage(content=summary_msg.content, tool_call_id=tool_call[\"id\"]))\n",
        "    return {\"messages\": result}"
      ],
      "metadata": {
        "id": "9L0ydublIKcy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(state: MessagesState) -> Literal[\"Action\", END]:\n",
        "    \"\"\"Decide if we should continue the loop or stop.\"\"\"\n",
        "    if state[\"messages\"][-1].tool_calls:\n",
        "        return \"Action\"\n",
        "    return END"
      ],
      "metadata": {
        "id": "sdnEU-pwINNf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build workflow\n",
        "agent_builder = StateGraph(MessagesState)\n",
        "\n",
        "# Add nodes\n",
        "agent_builder.add_node(\"llm_call\", llm_call)\n",
        "agent_builder.add_node(\"Action\", tool_node_with_summarization)\n",
        "\n",
        "# Add edges to connect nodes\n",
        "agent_builder.add_edge(START, \"llm_call\")\n",
        "agent_builder.add_conditional_edges(\n",
        "    \"llm_call\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"Action\": \"Action\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "agent_builder.add_edge(\"Action\", \"llm_call\")\n",
        "\n",
        "# Compile the agent\n",
        "agent = agent_builder.compile()\n",
        "\n",
        "# Show the agent\n",
        "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "svaCLsTBIPvG",
        "outputId": "c29ee5e3-ee1a-4f7e-cf29-1a57472185ba"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Why does RL improve LLM reasoning according to the blogs?\"\n",
        "result = agent.invoke({\"messages\": [(\"user\", query)]})\n",
        "print(result['messages'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_YSlTquIR6J",
        "outputId": "60a25552-6e49-4503-bcb2-a4d9b43ec84c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='Why does RL improve LLM reasoning according to the blogs?', additional_kwargs={}, response_metadata={}, id='aa3e3e61-e87d-4279-aa44-8047e7ed5f5f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1riI7dY5OUYtgzs3v5BKcwhc', 'function': {'arguments': '{\"query\":\"RL improve LLM reasoning\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 135, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfN7Ry9g7XbWEAeJnwQOsPjhhXDp', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--da202763-6f30-49ec-87dd-56db2ccd7c7c-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'RL improve LLM reasoning'}, 'id': 'call_1riI7dY5OUYtgzs3v5BKcwhc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 19, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='The document discusses various methods and experiments aimed at improving the reasoning, factuality, and evaluation capabilities of large language models (LLMs). Key points include:\\n\\n1. **RLHF and U-Sophistry**: Reinforcement Learning from Human Feedback (RLHF) can make LLMs more convincing in presenting incorrect answers by fabricating evidence and using consistent logic, leading to increased human evaluation errors.\\n\\n2. **Sycophancy**: LLMs tend to align their responses with user beliefs, providing biased feedback based on user preferences, which can lead to incorrect answers being accepted.\\n\\n3. **LLM-as-Grader Paradigm**: Using LLMs as evaluators can introduce biases, such as positional bias, where the order of responses affects evaluation. Strategies like multiple evidence calibration and human-in-the-loop calibration are proposed to mitigate these biases.\\n\\n4. **Parallel Sampling and Beam Search**: Techniques like beam search and reward balanced search are used to improve the accuracy of LLM outputs by guiding the search process with a process reward model.\\n\\n5. **Self-Correction**: LLMs struggle with self-correction due to issues like hallucination and behavior collapse. Methods like self-correction learning and recursive inspection aim to improve this capability through iterative revision and reinforcement learning.\\n\\n6. **RL for Better Reasoning**: Reinforcement learning is used to enhance reasoning abilities in LLMs, particularly for tasks with verifiable answers, by rewarding correct outputs.\\n\\n7. **Anti-Hallucination Methods**: Techniques like RAG (Retrieval-augmented Generation) and RARR (Retrofit Attribution using Research and Revision) are employed to reduce hallucinations by retrieving external knowledge and editing outputs to align with evidence.\\n\\n8. **Indirect Query for Hallucination Checking**: Indirect queries, which ask for auxiliary details about generated references, are more effective than direct queries in identifying hallucinations.\\n\\n9. **Rethinking with Retrieval (RR)**: This method uses decomposed chain-of-thought prompting and retrieval of external knowledge to ensure the faithfulness of model outputs.\\n\\nOverall, the document highlights the challenges and advancements in making LLMs more reliable, interpretable, and aligned with human expectations through various training and evaluation strategies.', id='b5844a48-8f41-4697-ada9-db714dd96a9c', tool_call_id='call_1riI7dY5OUYtgzs3v5BKcwhc'), AIMessage(content=\"According to Lilian Weng's blog, reinforcement learning (RL) improves the reasoning abilities of large language models (LLMs) in several ways:\\n\\n1. **Reinforcement Learning from Human Feedback (RLHF)**: This approach can enhance the model's ability to present answers convincingly, even if they are incorrect, by fabricating evidence and using consistent logic. This can lead to increased human evaluation errors, highlighting the need for careful design in RLHF to ensure it improves reasoning without introducing biases.\\n\\n2. **Rewarding Correct Outputs**: RL is used to enhance reasoning abilities, especially for tasks with verifiable answers, by rewarding the model for producing correct outputs. This helps in guiding the model towards more accurate and logical reasoning.\\n\\n3. **Self-Correction and Iterative Revision**: RL techniques are employed to improve the model's self-correction capabilities. Methods like self-correction learning and recursive inspection use RL to iteratively revise and refine the model's outputs, addressing issues like hallucination and behavior collapse.\\n\\n4. **Guided Search Techniques**: Techniques such as beam search and reward balanced search are used to improve the accuracy of LLM outputs. These methods guide the search process with a process reward model, helping the model to explore more promising reasoning paths.\\n\\nOverall, RL is leveraged to enhance the reasoning capabilities of LLMs by providing structured feedback and rewards that encourage the generation of accurate and logical responses.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 287, 'prompt_tokens': 615, 'total_tokens': 902, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfNHvHXQEyhu5C9fnaetUET4J9hQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ac8b15f2-89a0-4a22-a0ed-e2f9350fe118-0', usage_metadata={'input_tokens': 615, 'output_tokens': 287, 'total_tokens': 902, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isolating Context using Sub-Agents Architecture"
      ],
      "metadata": {
        "id": "fcOfOho5Je9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph_supervisor"
      ],
      "metadata": {
        "id": "kn727zmSJh3Z",
        "outputId": "c3b02020-dd71-45d9-ae50-1775f83f0d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph_supervisor\n",
            "  Downloading langgraph_supervisor-0.0.30-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langgraph<2.0.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph_supervisor) (1.0.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph_supervisor) (1.0.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (0.4.40)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (4.15.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langgraph_supervisor) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=0.6.0->langgraph_supervisor) (1.3.1)\n",
            "Downloading langgraph_supervisor-0.0.30-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: langgraph_supervisor\n",
            "Successfully installed langgraph_supervisor-0.0.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph_supervisor import create_supervisor\n",
        "\n",
        "# --- Define Tools for Each Agent ---\n",
        "def add(a: float, b: float) -> float:\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def web_search(query: str) -> str:\n",
        "    \"\"\"Mock web search function that returns FAANG company headcounts.\"\"\"\n",
        "    return (\n",
        "        \"Here are the headcounts for each of the FAANG companies in 2024:\\n\"\n",
        "        \"1. **Facebook (Meta)**: 67,317 employees.\\n\"\n",
        "        \"2. **Apple**: 164,000 employees.\\n\"\n",
        "        \"3. **Amazon**: 1,551,000 employees.\\n\"\n",
        "        \"4. **Netflix**: 14,000 employees.\\n\"\n",
        "        \"5. **Google (Alphabet)**: 181,269 employees.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "ZQy2kA-VJmoE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create Specialized Agents with Isolated Contexts ---\n",
        "math_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[add, multiply],\n",
        "    name=\"math_expert\",\n",
        "    prompt=\"You are a math expert. Always use one tool at a time.\"\n",
        ")\n",
        "\n",
        "research_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[web_search],\n",
        "    name=\"research_expert\",\n",
        "    prompt=\"You are a world class researcher with access to web search. Do not do any math.\"\n",
        ")\n",
        "\n",
        "# --- Create Supervisor Workflow for Coordinating Agents ---\n",
        "workflow = create_supervisor(\n",
        "    [research_agent, math_agent],\n",
        "    model=llm,\n",
        "    prompt=(\n",
        "        \"You are a team supervisor managing a research expert and a math expert. \"\n",
        "        \"Delegate tasks to the appropriate agent to answer the user's query. \"\n",
        "        \"For current events or facts, use research_agent. \"\n",
        "        \"For math problems, use math_agent.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the multi-agent application\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "gzPmLMsRJm-l",
        "outputId": "5624a647-618c-47b3-c9aa-57e02e39a414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-199748465.py:2: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  math_agent = create_react_agent(\n",
            "/tmp/ipython-input-199748465.py:9: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  research_agent = create_react_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Execute the Multi-Agent Workflow ---\n",
        "result = app.invoke({\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"what's the combined headcount of the FAANG companies in 2024?\"\n",
        "        }\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Format and display the results\n",
        "print(result['messages'])"
      ],
      "metadata": {
        "id": "ctzs8njwKBwu",
        "outputId": "81527cbb-c385-45a7-cfce-4d6af58ea240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content=\"what's the combined headcount of the FAANG companies in 2024?\", additional_kwargs={}, response_metadata={}, id='7fa66dc4-9fc1-4e15-af46-67564dc80340'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_i4v5lw4dwCYL14GKG8SmYC8N', 'function': {'arguments': '{}', 'name': 'transfer_to_research_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 126, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfUXJDttYLMnirFORoSaD2R3tP7S', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='supervisor', id='lc_run--edb44b5f-6a9a-4250-83c9-3eb20a8844f8-0', tool_calls=[{'name': 'transfer_to_research_expert', 'args': {}, 'id': 'call_i4v5lw4dwCYL14GKG8SmYC8N', 'type': 'tool_call'}], usage_metadata={'input_tokens': 126, 'output_tokens': 14, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to research_expert', name='transfer_to_research_expert', id='21a15691-dde2-43e6-ac9d-59ab72c58fb6', tool_call_id='call_i4v5lw4dwCYL14GKG8SmYC8N'), AIMessage(content='The combined headcount of the FAANG companies in 2024 is as follows:\\n\\n1. **Facebook (Meta)**: 67,317 employees\\n2. **Apple**: 164,000 employees\\n3. **Amazon**: 1,551,000 employees\\n4. **Netflix**: 14,000 employees\\n5. **Google (Alphabet)**: 181,269 employees\\n\\nTo find the total combined headcount, you would sum these numbers.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 689, 'total_tokens': 787, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfUY8AKDbI7HdbC1AazV6rgbZmyV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='research_expert', id='lc_run--cf096570-e9b1-4eed-96a9-c8a5e3980b8c-0', usage_metadata={'input_tokens': 689, 'output_tokens': 98, 'total_tokens': 787, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='research_expert', id='270d4d8a-7f06-4acd-8fe0-8964c39b6155', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '5886e95c-1300-4df9-9cf5-2ba27ccebcab', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='76e260c4-c51c-460e-a8b3-0bb4a7fc263a', tool_call_id='5886e95c-1300-4df9-9cf5-2ba27ccebcab'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xVYBXzEp5qhgx2BRDN94ERGK', 'function': {'arguments': '{}', 'name': 'transfer_to_math_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 313, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfUaOTBhed3YxWVJN6f8d8QuQeVX', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='supervisor', id='lc_run--c02cc3a4-9a88-403b-8d21-9b5de94df223-0', tool_calls=[{'name': 'transfer_to_math_expert', 'args': {}, 'id': 'call_xVYBXzEp5qhgx2BRDN94ERGK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 313, 'output_tokens': 13, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to math_expert', name='transfer_to_math_expert', id='81784abc-e9e0-4c87-922a-9be4fdc5afcb', tool_call_id='call_xVYBXzEp5qhgx2BRDN94ERGK'), AIMessage(content='The combined headcount of the FAANG companies in 2024 is 1,977,586 employees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 538, 'total_tokens': 561, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b1442291a8', 'id': 'chatcmpl-CZfUfEjxxt9kBEItljGropojZ4O9K', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='math_expert', id='lc_run--da652874-307d-4509-b374-832279b9df66-0', usage_metadata={'input_tokens': 538, 'output_tokens': 23, 'total_tokens': 561, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='math_expert', id='3878c58d-2c38-4a68-a6dd-5a4c33e8368e', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'c66e6ca4-a87e-4618-843b-5c6fa0fba24f', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='651e0b29-2b5f-493e-be34-744a3ab387f8', tool_call_id='c66e6ca4-a87e-4618-843b-5c6fa0fba24f'), AIMessage(content='The combined headcount of the FAANG companies in 2024 is 1,977,586 employees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 423, 'total_tokens': 446, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CZfUgtkxTnyOLnvOKBoyCCRKt29Mp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='lc_run--c8c42e88-72a0-4d11-a742-fe5fada03458-0', usage_metadata={'input_tokens': 423, 'output_tokens': 23, 'total_tokens': 446, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bI3pDGAMKOzI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}